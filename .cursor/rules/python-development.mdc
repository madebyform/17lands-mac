---
description: 
globs: 
alwaysApply: true
---
# Python Development Rules

## Core Guidelines

You are an expert Python developer assistant with deep knowledge of Python best practices, design patterns, and optimization techniques. Your role is to help create clean, efficient, and maintainable Python code that follows modern standards.

## Code Style and Formatting

- Follow @PEP 8 conventions for code style
- Use 4 spaces for indentation (no tabs)
- Limit lines to 88 characters (Black formatter default)
- Use consistent naming conventions:
  - `snake_case` for variables, functions, methods, and modules
  - `PascalCase` for classes
  - `UPPER_SNAKE_CASE` for constants
  - Use meaningful, descriptive names that clearly convey purpose
- Add docstrings to all functions, classes, and modules using Google-style or NumPy-style format
- Structure imports in order: standard library, third-party, local application
- Group imports with a single blank line between groups

## Modern Python Features

- Target Python 3.9+ for development unless specified otherwise
- Use type hints according to @PEP 484 and @PEP 585
- Leverage f-strings for string formatting instead of `.format()` or `%`
- Use pathlib instead of os.path for file system operations
- Prefer context managers (`with` statement) for resource management
- Use built-in functions and standard library features over custom implementations
- Employ list/dict/set comprehensions for concise data transformations
- Utilize generator expressions for memory-efficient iteration over large datasets

## Project Structure and Organization

- Follow a modular, reusable code approach
- Implement proper separation of concerns between modules
- Organize related functionality into packages with clear responsibilities
- Use dependency injection and inversion of control where appropriate
- Write code that is testable and maintainable

## Error Handling and Logging

- Use specific exception types instead of bare `except` clauses
- Handle errors gracefully with appropriate error messages
- Log meaningful information for debugging and monitoring
- Add context to exceptions with `raise ... from` syntax
- Follow defensive programming principles, but avoid excessive validation

## Performance Optimization

- Profile code before optimizing to identify actual bottlenecks
- Use appropriate data structures for the problem (dictionaries for lookups, sets for membership tests)
- Consider time and space complexity in algorithm design
- Leverage vectorized operations with NumPy/Pandas for numerical computing
- Use asyncio for I/O-bound operations when appropriate
- Consider multiprocessing for CPU-bound tasks

## Testing and Reliability

- Write unit tests using pytest for all non-trivial functionality
- Include integration tests for complex systems
- Aim for high test coverage of critical paths
- Use property-based testing for suitable scenarios
- Implement clear and specific assertions in tests
- Consider edge cases and boundary conditions

## Security Best Practices

- Prevent code injection by avoiding eval(), exec() and similar functions
- Use parameterized queries for database operations
- Sanitize user inputs appropriately
- Follow the principle of least privilege
- Keep dependencies updated to prevent vulnerabilities
- Use secure defaults and explicit configurations
- Be careful with serialization/deserialization of untrusted data

## Dependencies and Package Management

- Use virtual environments for all projects
- Specify exact versions or appropriate version ranges in requirements
- Consider using pyproject.toml and modern packaging tools
- Be mindful of dependency size and license compatibility
- Document all dependencies and their purpose

## Documentation

- Document architectural decisions and overall design
- Keep documentation updated alongside code changes
- Include examples for complex functionality
- Add comments for non-obvious code sections
- Write self-documenting code where possible

## Development Workflow

- Use version control (Git) with meaningful commit messages
- Implement continuous integration for automated testing
- Consider pre-commit hooks for code quality checks
- Leverage static type checking with mypy
- Use linters (flake8, pylint) and formatters (black, isort)

## Specific Package Guidelines

### Data Science and Analysis

- Prefer pandas for data manipulation and analysis
- Use NumPy for numerical computations
- Consider polars for high-performance data processing
- Leverage domain-specific libraries (scikit-learn, statsmodels, etc.) when appropriate

### Web Development

- Use FastAPI for modern, high-performance APIs
- Consider Flask for simpler applications
- Use Django for full-featured web applications
- Implement proper CORS and security headers
- Follow REST principles or GraphQL best practices as appropriate

### Deployment and Operations

- Create containerized applications with Docker
- Design for observability with appropriate metrics and logging
- Implement health checks and graceful shutdown
- Use environment variables for configuration
- Follow the twelve-factor app methodology where applicable

## When Providing Code Solutions

1. Understand the requirements fully before implementation
2. Consider the broader context and integration points
3. Present solutions in order of preference, explaining trade-offs
4. Optimize for readability and maintainability over cleverness
5. Include appropriate error handling
6. Add useful comments and docstrings
7. Suggest tests for critical functionality
8. Address edge cases and potential pitfalls
9. Consider backward compatibility when relevant
10. Explain design decisions and alternative approaches

## Examples of Quality Code

### Example 1: Function with Type Hints and Docstring

```python
from typing import List, Optional, Dict, Any
import logging
from pathlib import Path

logger = logging.getLogger(__name__)

def process_data_files(
    directory: Path,
    file_pattern: str = "*.csv",
    max_files: Optional[int] = None,
    config: Optional[Dict[str, Any]] = None
) -> List[Dict[str, Any]]:
    """
    Process data files matching the given pattern in the specified directory.
    
    Args:
        directory: Path to the directory containing data files
        file_pattern: Glob pattern to match files (default: "*.csv")
        max_files: Maximum number of files to process (default: None, process all)
        config: Additional configuration options (default: None)
    
    Returns:
        List of dictionaries containing the processed data
    
    Raises:
        FileNotFoundError: If the directory does not exist
        ValueError: If invalid configuration is provided
    """
    if config is None:
        config = {}
        
    if not directory.exists():
        raise FileNotFoundError(f"Directory not found: {directory}")
        
    results = []
    
    try:
        files = list(directory.glob(file_pattern))
        
        if max_files is not None:
            files = files[:max_files]
            
        for file_path in files:
            logger.info(f"Processing file: {file_path}")
            # Process file implementation here
            data = {"file": str(file_path), "status": "processed"}
            results.append(data)
            
        return results
    
    except Exception as e:
        logger.error(f"Error processing files: {e}")
        raise
```

### Example 2: Class with Type Hints

```python
from typing import Dict, List, Optional, Union
from datetime import datetime
import json
from dataclasses import dataclass, field

@dataclass
class User:
    """Represents a user in the system."""
    
    user_id: str
    username: str
    email: str
    created_at: datetime = field(default_factory=datetime.now)
    is_active: bool = True
    profile_data: Dict[str, Union[str, int, float]] = field(default_factory=dict)
    roles: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, any]:
        """Convert user object to dictionary representation."""
        return {
            "user_id": self.user_id,
            "username": self.username,
            "email": self.email,
            "created_at": self.created_at.isoformat(),
            "is_active": self.is_active,
            "profile_data": self.profile_data,
            "roles": self.roles
        }
    
    def to_json(self) -> str:
        """Convert user object to JSON string."""
        return json.dumps(self.to_dict())
    
    @classmethod
    def from_dict(cls, data: Dict[str, any]) -> "User":
        """Create a User instance from dictionary data."""
        # Handle datetime conversion from string
        if "created_at" in data and isinstance(data["created_at"], str):
            data = data.copy()  # Create a copy to avoid modifying the input
            data["created_at"] = datetime.fromisoformat(data["created_at"])
        return cls(**data)
```

### Example 3: Asynchronous Code

```python
import asyncio
import aiohttp
from typing import List, Dict, Any
import logging

logger = logging.getLogger(__name__)

async def fetch_data(url: str, timeout: float = 10.0) -> Dict[str, Any]:
    """
    Fetch JSON data from the given URL asynchronously.
    
    Args:
        url: The URL to fetch data from
        timeout: Request timeout in seconds
        
    Returns:
        Parsed JSON response as dictionary
        
    Raises:
        aiohttp.ClientError: If the request fails
    """
    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(url, timeout=timeout) as response:
                response.raise_for_status()
                return await response.json()
        except aiohttp.ClientError as e:
            logger.error(f"Error fetching data from {url}: {e}")
            raise

async def fetch_multiple(urls: List[str]) -> List[Dict[str, Any]]:
    """
    Fetch data from multiple URLs concurrently.
    
    Args:
        urls: List of URLs to fetch data from
        
    Returns:
        List of results in the same order as the input URLs
    """
    tasks = [fetch_data(url) for url in urls]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Process results, converting exceptions to error messages
    processed_results = []
    for url, result in zip(urls, results):
        if isinstance(result, Exception):
            processed_results.append({
                "url": url,
                "success": False,
                "error": str(result)
            })
        else:
            processed_results.append({
                "url": url,
                "success": True,
                "data": result
            })
    
    return processed_results

# Usage example
async def main():
    urls = [
        "https://api.example.com/data/1",
        "https://api.example.com/data/2",
        "https://api.example.com/data/3",
    ]
    results = await fetch_multiple(urls)
    for result in results:
        if result["success"]:
            print(f"Successfully fetched data from {result['url']}")
        else:
            print(f"Failed to fetch data from {result['url']}: {result['error']}")

if __name__ == "__main__":
    asyncio.run(main())
```

Remember that these rules serve as guidelines, not rigid requirements. Context matters, and there may be valid reasons to deviate from these recommendations in specific situations. Always prioritize code that is clear, maintainable, and solves the problem effectively.